{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Efyopufmg5"
      },
      "source": [
        "# Solving video games with *Artificial Intelligence* and *Evolution*\n",
        "\n",
        "\u003ca href=\"https://colab.research.google.com/github/deepmind/educational/blob/master/colabs/introductory/fluttering_avians.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH-p2O86DmVQ"
      },
      "source": [
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003eCopyright 2021 DeepMind Technologies Limited.\u003c/small\u003e\u003c/small\u003e\u003c/p\u003e\n",
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003e Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at \u003c/small\u003e\u003c/small\u003e\u003c/p\u003e\n",
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003e \u003ca href=\"https://www.apache.org/licenses/LICENSE-2.0\"\u003ehttps://www.apache.org/licenses/LICENSE-2.0\u003c/a\u003e \u003c/small\u003e\u003c/small\u003e\u003c/p\u003e\n",
        "\u003e \u003cp\u003e\u003csmall\u003e\u003csmall\u003e Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. \u003c/small\u003e\u003c/small\u003e\u003c/p\u003e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10sYbheuDiZ3"
      },
      "source": [
        "\n",
        "**Aim of this Colab**\n",
        "\n",
        "Give you basic intuition on Artificial Intelligence and how Evolution fits into it. It does so by walking you through developing an agent to play a video game.\n",
        "\n",
        "**Disclaimer**\n",
        "\n",
        "This code is intended for educational purposes and, in the name of usability by a non-technical audience, it does not always follow best practices for software engineering.\n",
        "\n",
        "All images are copyright of Alphabet Inc.\n",
        "\n",
        "**Links to resources**\n",
        "- [What is Colab?](https://colab.research.google.com/notebooks/intro.ipynb) If you have never used Colab before, get started here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ROqhpE6EutU"
      },
      "source": [
        "# Artificial Intelligence and Games"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbhYBi0yA7bT"
      },
      "source": [
        "## What do we mean by Artificial Intelligence?\n",
        "\n",
        "Usually, when we think of *Artificial Intelligence* (or *AI*) in games, we think of the opponents *being programmed* to pose a challenge. These opponents adapt their strategy based on the difficulty level, or even our actions.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/fighting.png\" width=\"500\"/\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "However, here we are talking of a different kind of AI. The whole idea is to create *something* that can play the game the way a person would, that is, by using a (virtual) controller with the same functionality as the one that *we* would use to play the game.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/robot_playing.png\" width=\"250\"/\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "We refer to this *something* as an **agent**. Agents interact with an **environment** via *actions* (e.g. buttons pressed). The environment is the game, and the agent is the player.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/rl_setting.png\" width=\"500\"/\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "The goal of the agent is to get the highest possible *score* in the game, or, as we say in the AI community, to maximise its *reward*.\n",
        "\n",
        "-------\n",
        "\n",
        "But first, let's have some fun playing the game! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqbVm_6aBFuL"
      },
      "source": [
        "# Fluttering Avians\n",
        "\n",
        "*Fluttering Avians* is a game we made so you could learn about *Artificial Intelligence*. It is similar to the famous [*Flappy Bird*](https://en.wikipedia.org/wiki/Flappy_Bird) game of 2013.\n",
        "\n",
        "------\n",
        "\n",
        "Place your mouse next to the `[ ]` sign in a cell, it should change to a play button ▶️. Click the play button to run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "waRRl_76BI7z"
      },
      "outputs": [],
      "source": [
        "#@title Run your first cell!\n",
        "\n",
        "print(\"Yay! you just ran the cell!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWHvmY9KBLw7"
      },
      "source": [
        "If you ran the cell correctly, you should see:\n",
        "\n",
        "`Yay! you just ran the cell!`\n",
        "\n",
        "\n",
        "------\n",
        "\n",
        "Now, let's get all the code and libraries we need to create a *Fluttering Avians* environment. Run the cell below. It should take less than a minute to complete.\n",
        "\n",
        "Don't worry, you don't need to understand how this is happening, but if you are curious, you can take a peek at the actual code by double-clicking the cell below; the one that is called: `Set up the code for the Fluttering Avians environment`.\n",
        "\n",
        "This will open up the whole code so you can see it. You can hide it again by double-clicking on the name (which will be to the right of the code) again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xcrUR8ZqzHsA"
      },
      "outputs": [],
      "source": [
        "#@title Set up the code for the Fluttering Avians environment\n",
        "\n",
        "%%capture\n",
        "\n",
        "!pip install dm_env\n",
        "!pip install colabtools\n",
        "\n",
        "from base64 import b64encode\n",
        "import copy\n",
        "import dm_env\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "import threading\n",
        "import tree\n",
        "import time\n",
        "\n",
        "from google.colab import output\n",
        "import IPython\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "\n",
        "def load_resource(url):\n",
        "  r = requests.get(\n",
        "      'https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/' +\n",
        "      '{}'.format(url), stream=True)\n",
        "  return PIL.Image.open(BytesIO(r.content)).convert()\n",
        "\n",
        "def load_font(size=18):\n",
        "  r = requests.get(\n",
        "      'https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/' +\n",
        "      'Roboto-Regular.ttf', stream=True)\n",
        "  return PIL.ImageFont.truetype(BytesIO(r.content), size)\n",
        "\n",
        "def encode_observation(ts):\n",
        "  b = BytesIO()\n",
        "  ts.observation['Pixels'].save(b, format='png')\n",
        "  return b64encode(b.getvalue()).decode('utf-8')\n",
        "\n",
        "\n",
        "class FlutteringAvians(dm_env.Environment):\n",
        "\n",
        "  def __init__(self, render_pixels: bool = True, flutter_speed: float = 0.02,\n",
        "               pipe_speed: float = 0.02, pipe_hole_size: float = 0.2,\n",
        "               flutter_up_angle: float = 30, flutter_down_angle: float = 175,\n",
        "               flutter_angle_delta: float = 10, frames_per_pipe: int = 30):\n",
        "    \"\"\"Fluttering Avians is a fast-paced, obstacle-avoidance, auto-scoller.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the sprites\n",
        "    self._bg = load_resource('Background.png')\n",
        "    self._pipes_up = load_resource('Obstacle_From_Top.png')\n",
        "    self._pipes_dn = load_resource('Obstacle_From_Bottom.png')\n",
        "    self._flutter1 = load_resource('Red_Bird_Wing_Down.png')\n",
        "    self._flutter2 = load_resource('Red_Bird_Wing_Mid.png')\n",
        "    self._flutter3 = load_resource('Red_Bird_Wing_Up.png')\n",
        "    self._flappies = [\n",
        "        self._flutter1, self._flutter2, self._flutter3, self._flutter2]\n",
        "\n",
        "    # The background image sets the whole frame size\n",
        "    self._width = self._bg.size[0]\n",
        "    self._height = self._bg.size[1]\n",
        "\n",
        "    self._render_pixels = render_pixels\n",
        "    self._flutter_speed = flutter_speed * self._height\n",
        "    self._pipe_speed = pipe_speed * self._width\n",
        "    self._pipe_hole_size = pipe_hole_size * self._height\n",
        "\n",
        "    # Angles are given clockwise, 0 pointing up.\n",
        "    self._flutter_up_angle = flutter_up_angle\n",
        "    self._flutter_down_angle = flutter_down_angle\n",
        "    self._flutter_angle_delta = flutter_angle_delta\n",
        "    self._frames_per_pipe = frames_per_pipe\n",
        "    self._sprite_count_frames = 3\n",
        "\n",
        "    self._max_pipes = int(\n",
        "        self._width / self._pipe_speed / self._frames_per_pipe) + 2\n",
        "\n",
        "    self._font = load_font(32)\n",
        "    self._score_font = load_font(18)\n",
        "    self._init_state()\n",
        "\n",
        "  def _init_state(self):\n",
        "    self._flutter_angle = 60\n",
        "    self._flutter_x = self._width * 0.25\n",
        "    self._flutter_y = self._height * 0.5\n",
        "    self._score = 0\n",
        "    self._next_pipe = self._frames_per_pipe\n",
        "    # Put first pipe in state.\n",
        "    self._current_pipes = []\n",
        "    self._add_pipe()\n",
        "    self._game_over_flag = False\n",
        "    self._sprite_count = 0\n",
        "\n",
        "  def _add_pipe(self):\n",
        "    # Minimum distance from edge of screen the hole of the pipe can be.\n",
        "    bounds = 150\n",
        "    self._current_pipes.append(\n",
        "        [self._width + self._pipes_up.size[0],\n",
        "         np.random.randint(bounds, self._height - bounds)])\n",
        "\n",
        "  def _get_frame(self):\n",
        "    frame = self._bg.copy()\n",
        "    flutter = self._flappies[self._sprite_count // self._sprite_count_frames %\n",
        "                            len(self._flappies)]\n",
        "\n",
        "    sprite = flutter.rotate(90 - self._flutter_angle,\n",
        "                            resample=PIL.Image.BICUBIC, expand=True)\n",
        "    flutter_sz = sprite.size\n",
        "    frame.paste(sprite,\n",
        "                (int(self._flutter_x - flutter_sz[0]/2),\n",
        "                 int(self._flutter_y - flutter_sz[1]/2)),\n",
        "                sprite)\n",
        "    pipe_sz = self._pipes_up.size\n",
        "    for pipe in self._current_pipes:\n",
        "      frame.paste(self._pipes_up,\n",
        "                  (int(pipe[0] - pipe_sz[0]/2),\n",
        "                   int(pipe[1] - pipe_sz[1] - self._pipe_hole_size/2)),\n",
        "                  self._pipes_up)\n",
        "      frame.paste(self._pipes_dn,\n",
        "                  (int(pipe[0] - pipe_sz[0]/2),\n",
        "                   int(pipe[1] + self._pipe_hole_size/2)),\n",
        "                  self._pipes_dn)\n",
        "    draw = ImageDraw.Draw(frame)\n",
        "    if self._game_over_flag:\n",
        "      draw.text((50, 160), \"GAME OVER\", (204, 136, 204), font=self._font)\n",
        "    draw.text((20, 20), f\"Score: {int(self._score)}\",\n",
        "              (0, 0, 0), font=self._score_font)\n",
        "    return frame\n",
        "\n",
        "  def _get_observation(self):\n",
        "    # Copy the pipes\n",
        "    pipes = self._current_pipes[:]\n",
        "    assert len(pipes) \u003c= self._max_pipes\n",
        "    while len(pipes) \u003c self._max_pipes:\n",
        "      pipes.append([0, 0])\n",
        "    obs = {\n",
        "        'Features': {\n",
        "            'angle': self._flutter_angle,\n",
        "            'x': self._flutter_x,\n",
        "            'y': self._flutter_y,\n",
        "            'pipes': pipes,\n",
        "        }}\n",
        "    if self._render_pixels:\n",
        "      obs['Pixels'] = self._get_frame()\n",
        "    return obs\n",
        "\n",
        "  def _collides_with_pipe(self, pipe, point):\n",
        "    clearance_x = self._pipes_up.size[0] + self._flutter1.size[0]*0.75\n",
        "    if (pipe[0] + clearance_x/2 \u003e= point[0] \u003e= pipe[0] - clearance_x/2):\n",
        "      clearance_y = self._pipe_hole_size - self._flutter1.size[1]*0.75\n",
        "      if (pipe[1] + clearance_y/2 \u003e= point[1] \u003e= pipe[1] - clearance_y/2):\n",
        "        return False\n",
        "      else:\n",
        "        return True\n",
        "      return False\n",
        "\n",
        "  def reset(self):\n",
        "    self._init_state()\n",
        "\n",
        "    return dm_env.TimeStep(\n",
        "        step_type=dm_env.StepType.FIRST,\n",
        "        reward=0,\n",
        "        discount=1.0,\n",
        "        observation=self._get_observation())\n",
        "\n",
        "  def step(self, action):\n",
        "    if self._game_over_flag:\n",
        "      return self.reset()\n",
        "\n",
        "    reward = 0\n",
        "    self._next_pipe -= 1\n",
        "    self._sprite_count += 1\n",
        "    if self._next_pipe \u003c= 0:\n",
        "      self._next_pipe = self._frames_per_pipe\n",
        "      self._add_pipe()\n",
        "\n",
        "    self._flutter_y -= self._flutter_speed * math.cos(\n",
        "        math.radians(self._flutter_angle))\n",
        "\n",
        "    if action:\n",
        "      self._flutter_angle = self._flutter_up_angle\n",
        "    else:\n",
        "      self._flutter_angle = min(\n",
        "          self._flutter_down_angle,\n",
        "          self._flutter_angle + self._flutter_angle_delta)\n",
        "\n",
        "    # If the pipe has left the screen, remove it\n",
        "    if self._current_pipes[0][0] \u003c -self._pipes_up.size[0]:\n",
        "      self._current_pipes = self._current_pipes[1:]\n",
        "\n",
        "    for pipe in self._current_pipes:\n",
        "      pipe[0] -= self._pipe_speed\n",
        "      if self._collides_with_pipe(pipe, [self._flutter_x, self._flutter_y]):\n",
        "        reward = -1\n",
        "\n",
        "    if self._flutter_y \u003e= self._height or self._flutter_y \u003c= 0:\n",
        "      # End episode, show game over.\n",
        "      reward = -1\n",
        "\n",
        "    self._score += 1.0/self._frames_per_pipe\n",
        "\n",
        "    if reward \u003c 0:\n",
        "      self._game_over_flag = True\n",
        "\n",
        "    obs = self._get_observation()\n",
        "    return dm_env.TimeStep(\n",
        "        step_type=dm_env.StepType.MID if reward \u003e= 0 else dm_env.StepType.LAST,\n",
        "        reward=reward,\n",
        "        discount=1.0,\n",
        "        observation=obs)\n",
        "\n",
        "  def action_spec(self):\n",
        "    dm_env.specs.DiscreteArray(2)\n",
        "\n",
        "  def observation_spec(self):\n",
        "    spec = {\n",
        "        'Features': {\n",
        "            'angle': dm_env.specs.Array([], np.float32),\n",
        "            'x': dm_env.specs.Array([], np.float32),\n",
        "            'y': dm_env.specs.Array([], np.float32),\n",
        "            'pipes': dm_env.specs.Array([self._max_pipes, 2], np.float32),\n",
        "        }\n",
        "    }\n",
        "    if self._render_pixels:\n",
        "      spec['Pixels'] = dm_env.specs.Array(\n",
        "          [self._bg.size[0], self._bg.size[1], 4], np.uint8)\n",
        "    return spec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_trace(agent, env, max_steps: int = 500):\n",
        "  ts = env.reset()\n",
        "  trace = [ts.observation]\n",
        "  while ts.step_type != dm_env.StepType.LAST and max_steps \u003e 0:\n",
        "    policy_val = agent.step(ts.observation)\n",
        "    action = 1 if policy_val \u003e 0.5 else 0\n",
        "    ts = env.step(action)\n",
        "    trace.append(ts.observation)\n",
        "    max_steps -= 1\n",
        "  return trace\n",
        "\n",
        "def prepare_animation():\n",
        "  fig, ax = plt.subplots()\n",
        "  fig.set_figheight(512/60)\n",
        "  fig.set_figwidth(288/60)\n",
        "  ax.grid(False)\n",
        "  ax.axis('off')\n",
        "  image = ax.imshow(np.zeros([512, 288, 4]), aspect='equal')\n",
        "  return fig, ax, image\n",
        "\n",
        "\n",
        "\n",
        "env = FlutteringAvians()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzbChxMnB-eK"
      },
      "source": [
        "Now we can play the game!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QwXgS6K0FRtG"
      },
      "outputs": [],
      "source": [
        "#@title Play the game!\n",
        "\n",
        "#@markdown Avoid the obstacles! Click the image to flutter up.\n",
        "\n",
        "def encode_image(img):\n",
        "  b = BytesIO()\n",
        "  img.save(b, format='png')\n",
        "  return b64encode(b.getvalue()).decode('utf-8')\n",
        "\n",
        "IPython.display.display(IPython.display.Javascript('''\n",
        "bgimage = new Image();\n",
        "bgimage.src = 'data:image/png;base64,{}';\n",
        "\n",
        "flutter1image = new Image();\n",
        "flutter1image.src = 'data:image/png;base64,{}';\n",
        "flutter2image = new Image();\n",
        "flutter2image.src = 'data:image/png;base64,{}';\n",
        "flutter3image = new Image();\n",
        "flutter3image.src = 'data:image/png;base64,{}';\n",
        "\n",
        "pipesupimage = new Image();\n",
        "pipesupimage.src = 'data:image/png;base64,{}';\n",
        "pipesdnimage = new Image();\n",
        "pipesdnimage.src = 'data:image/png;base64,{}';\n",
        "\n",
        "'''.format(encode_image(env._bg),\n",
        "           encode_image(env._flutter1),\n",
        "           encode_image(env._flutter2),\n",
        "           encode_image(env._flutter3),\n",
        "           encode_image(env._pipes_up),\n",
        "           encode_image(env._pipes_dn),\n",
        "           )))\n",
        "\n",
        "IPython.display.display(IPython.display.HTML('''\n",
        "\u003ccenter\u003e\n",
        "\u003cdiv id='maindiv'\u003e\n",
        "\u003ccanvas id='canvas' width=\"288\" height=\"512\"\n",
        "style=\"border:3px solid #616161;\"\u003e\u003c/canvas\u003e\n",
        "\u003c/div\u003e\n",
        "\u003cdiv id='play_button_div'\u003e\n",
        "\u003cbutton onclick=\"restart()\"\u003eRestart game\u003c/button\u003e\n",
        "\u003c/div\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "\u003cscript\u003e\n",
        "bg_w = 288\n",
        "bg_h = 512\n",
        "flutter_w = 31\n",
        "flutter_h = 23\n",
        "pipe_w = 52\n",
        "pipe_h = 320\n",
        "\n",
        "class FlutteringAvians {\n",
        "  constructor(flutter_speed = 0.02, pipe_speed = 0.02,\n",
        "              pipe_hole_size = 0.2, flutter_up_angle = 30,\n",
        "              flutter_down_angle = 175, flutter_angle_delta = 10,\n",
        "              frames_per_pipe = 30) {\n",
        "    this._flappies = [\n",
        "        flutter1image, flutter2image, flutter3image, flutter2image];\n",
        "\n",
        "    // The background image sets the whole frame size\n",
        "    this._width = bg_w;\n",
        "    this._height = bg_h;\n",
        "\n",
        "    this._flutter_speed = flutter_speed * this._height;\n",
        "    this._pipe_speed = pipe_speed * this._width;\n",
        "    this._pipe_hole_size = pipe_hole_size * this._height;\n",
        "\n",
        "    // Angles are given clockwise, 0 pointing up.\n",
        "    this._flutter_up_angle = flutter_up_angle;\n",
        "    this._flutter_down_angle = flutter_down_angle;\n",
        "    this._flutter_angle_delta = flutter_angle_delta;\n",
        "    this._frames_per_pipe = frames_per_pipe;\n",
        "    this._sprite_count_frames = 3;\n",
        "\n",
        "    this._max_pipes = parseInt(\n",
        "        this._width / this._pipe_speed / this._frames_per_pipe) + 2;\n",
        "\n",
        "    this._init_state();\n",
        "  }\n",
        "\n",
        "  _init_state() {\n",
        "    this._flutter_angle = 60;\n",
        "    this._flutter_x = this._width * 0.25;\n",
        "    this._flutter_y = this._height * 0.5;\n",
        "    this._score = 0;\n",
        "    this._next_pipe = this._frames_per_pipe;\n",
        "    // Put first pipe in state.\n",
        "    this._current_pipes = [];\n",
        "    this._add_pipe();\n",
        "    this._game_over_flag = false;\n",
        "    this._sprite_count = 0;\n",
        "  }\n",
        "\n",
        "  _add_pipe() {\n",
        "    // Minimum distance from edge of screen the hole of the pipe can be.\n",
        "    var bounds = 150;\n",
        "    this._current_pipes.push(\n",
        "        [this._width + pipe_w,\n",
        "         Math.random() * (this._height - 2*bounds) + bounds]);\n",
        "  }\n",
        "\n",
        "  _draw_frame() {\n",
        "    var c = document.getElementById(\"canvas\");\n",
        "    var ctx = c.getContext(\"2d\");\n",
        "\n",
        "    var flutter = this._flappies[\n",
        "      parseInt(this._sprite_count / this._sprite_count_frames) %\n",
        "      this._flappies.length];\n",
        "\n",
        "    ctx.drawImage(bgimage, 0, 0)\n",
        "    for (var i = 0; i \u003c this._current_pipes.length; i++) {\n",
        "      var pipe = this._current_pipes[i];\n",
        "      ctx.drawImage(pipesupimage,\n",
        "                    pipe[0] - pipe_w/2,\n",
        "                    pipe[1] - pipe_h - this._pipe_hole_size/2);\n",
        "      ctx.drawImage(pipesdnimage,\n",
        "                    pipe[0] - pipe_w/2,\n",
        "                    pipe[1] + this._pipe_hole_size/2);\n",
        "    }\n",
        "    if (this._game_over_flag) {\n",
        "      ctx.font = \"32px Arial\";\n",
        "      ctx.fillStyle = \"#CC88CC\";\n",
        "      ctx.fillText(\"GAME OVER\", 50, 160);\n",
        "    }\n",
        "    ctx.font = \"18px Arial\";\n",
        "    ctx.fillStyle = \"#000000\";\n",
        "    ctx.fillText(\"Score: \" + Math.floor(this._score), 20, 20);\n",
        "    var rot = Math.PI * (this._flutter_angle - 90) / 180.0;\n",
        "    var x = this._flutter_x;\n",
        "    var y = this._flutter_y;\n",
        "    ctx.translate(x, y);\n",
        "    ctx.rotate(rot);\n",
        "    ctx.drawImage(flutter, -flutter_w/2, -flutter_h/2);\n",
        "    ctx.rotate(-rot);\n",
        "    ctx.translate(-x, -y);\n",
        "  }\n",
        "\n",
        "  _collides_with_pipe(pipe, point) {\n",
        "    var clearance_x = pipe_w + flutter_w*0.75\n",
        "    if (pipe[0] + clearance_x/2 \u003e= point[0] \u0026\u0026\n",
        "        point[0] \u003e= pipe[0] - clearance_x/2) {\n",
        "      var clearance_y = this._pipe_hole_size - flutter_h*0.75;\n",
        "      if (pipe[1] + clearance_y/2 \u003e= point[1] \u0026\u0026\n",
        "          point[1] \u003e= pipe[1] - clearance_y/2) {\n",
        "        return false;\n",
        "      }\n",
        "      else { return true; }\n",
        "      return false;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  reset() {\n",
        "    this._init_state();\n",
        "  }\n",
        "\n",
        "  step(action) {\n",
        "    if (this._game_over_flag) {\n",
        "      this.reset();\n",
        "    }\n",
        "\n",
        "    var reward = 0;\n",
        "    this._next_pipe -= 1;\n",
        "    this._sprite_count += 1;\n",
        "    if (this._next_pipe \u003c= 0) {\n",
        "      this._next_pipe = this._frames_per_pipe;\n",
        "      this._add_pipe();\n",
        "    }\n",
        "\n",
        "    this._flutter_y -= this._flutter_speed * Math.cos(\n",
        "        Math.PI * this._flutter_angle / 180.0);\n",
        "\n",
        "    if (action) {\n",
        "      this._flutter_angle = this._flutter_up_angle;\n",
        "    }\n",
        "    else {\n",
        "      this._flutter_angle = Math.min(\n",
        "          this._flutter_down_angle,\n",
        "          this._flutter_angle + this._flutter_angle_delta);\n",
        "    }\n",
        "\n",
        "    // If the pipe has left the screen, remove it\n",
        "    if (this._current_pipes[0][0] \u003c -this._pipe_w) {\n",
        "      this._current_pipes = this._current_pipes.slice(\n",
        "          1, this._current_pipes.length);\n",
        "    }\n",
        "\n",
        "    for ( var i = 0; i \u003c this._current_pipes.length; i++ ) {\n",
        "      var pipe = this._current_pipes[i];\n",
        "      pipe[0] -= this._pipe_speed;\n",
        "      if (this._collides_with_pipe(pipe, [this._flutter_x, this._flutter_y])) {\n",
        "        reward = -1;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    if (this._flutter_y \u003e= this._height || this._flutter_y \u003c= 0) {\n",
        "      // End episode, show game over.\n",
        "      reward = -1;\n",
        "    }\n",
        "\n",
        "    this._score += 1.0/this._frames_per_pipe;\n",
        "\n",
        "    if (reward \u003c 0) {\n",
        "      this._game_over_flag = true;\n",
        "    }\n",
        "\n",
        "    // Render frame\n",
        "    this._draw_frame();\n",
        "\n",
        "    return reward;\n",
        "  }\n",
        "};\n",
        "\n",
        "window.onload = function() {\n",
        "  var c = document.getElementById(\"canvas\");\n",
        "  var ctx = c.getContext(\"2d\");\n",
        "  var img = document.getElementById(\"img\");\n",
        "  ctx.drawImage(img, 10, 10, 150, 180);\n",
        "};\n",
        "\n",
        "env = new FlutteringAvians();\n",
        "console.log('Loaded environment');\n",
        "myStepFn = null\n",
        "\n",
        "const move = () =\u003e {\n",
        "  action = 1;\n",
        "}\n",
        "const step = () =\u003e {\n",
        "  var reward = env.step(action);\n",
        "  action = 0;\n",
        "  stepCount++;\n",
        "  if (reward \u003c 0) {\n",
        "    clearInterval(myStepFn);\n",
        "  }\n",
        "}\n",
        "const restart = () =\u003e {\n",
        "  action = 0;\n",
        "  env.reset();\n",
        "  clearInterval(myStepFn);\n",
        "  myStepFn = setInterval(step, 50);\n",
        "  stepCount = 0;\n",
        "}\n",
        "\n",
        "restart();\n",
        "\n",
        "document.getElementById(\"canvas\").addEventListener('click', move);\n",
        "\u003c/script\u003e\n",
        "'''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_C0NvToCWtW"
      },
      "source": [
        "That's a hard game, huh?\n",
        "\n",
        "Imagine a computer that would be able to learn to play perfectly and get the maximum score!\n",
        "\n",
        "Well, that's what AI is all about. In particular, *Machine Learning*, a subfield of AI, studies how to make machines that *learn* directly from their own experience through trial and error, similar to the way *we* learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDzOzF3UR_Bc"
      },
      "source": [
        "# This agent plays the game, so you don't have to!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orgjbh_jCZh9"
      },
      "source": [
        "An *agent* is anything that observes the current situation in the game (what we call a **state**) and chooses which action to take. In our case, whether to flutter or not.\n",
        "\n",
        "Our game looks like this:\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/fluttering_avians.png\" width=\"200\"/\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "So we can define our state to be made up of:\n",
        "\n",
        "3. The current **_y_-coordinate** of the character\n",
        "1. The current **angle** of the character\n",
        "2. The **distance** to the next obstacle\n",
        "4. The **height** of the hole in the obstacle\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/features.png\" width=\"200\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "We take those four numbers, and we plug them into our agent. Out the other side we get the action.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/agent.png\" width=\"500\"/\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "Do you think you could think of a way to combine those four values to choose the right action for any state?\n",
        "\n",
        "In many ways, this is what programmers do all the time! We write the code inside of those agents so that they do what we need them to. A simple idea would be to check if **our height** is similar to the **height of the hole**. If we are too low, we need to flutter! That function would look like:\n",
        "\n",
        "```python\n",
        "def fluttering_agent(y_coord, angle, distance, height):\n",
        "  if y_coord \u003e height:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "```\n",
        "\n",
        "The arguments (inputs) to the function implementing our agent are:\n",
        "*   **`y_coord`**: The **_y_** coordinate of the character. `0` is at the top of the screen, the maximum value is `512` at the bottom of the screen.\n",
        "*   **`angle`**: The angle of the character. These are measured clockwise in degrees starting at the top for `0`, right for `90`, down for `180`. Fluttering sets this angle to `30`. The maximum angle, when nose-diving, is `175`.\n",
        "*   **`distance`**: The distance to the center of the next obstacle. This is always a positive number. The width of the screen is `288`. Our character is `72` pixels from the left edge.\n",
        "*   **`height`**: The height in pixels of the center of the hole in the obstacle. Obstacles have an opening of `102` pixels. This is in the same units as **`y_coord`**.\n",
        "  \n",
        "The function should return either `0` for no action, or `1` to flutter.\n",
        "\n",
        "-----\n",
        "\n",
        "Give it a go! Improve the function in any way you want and see how your *agent* fares. :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20uooBHSovyh"
      },
      "source": [
        "## Hand-code the agent!\n",
        "\n",
        "**NOTE**: Don't forget to run the cell with your function once you've written it (and any time you change it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Z3TNNxmGEVN9"
      },
      "outputs": [],
      "source": [
        "def fluttering_agent(y_coord, angle, distance, height):\n",
        "  # Your code goes below here.\n",
        "  \n",
        "  return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF8rLdiBIf-j"
      },
      "source": [
        "### One possible solution\n",
        "\n",
        "Below is a manually written black box function that mostly works :). You can show it if you click on the _`↳ 1 cell hidden`_ message below.\n",
        "\n",
        "The solution is not perfect, but it shows that this kind of function can be written, at least *in principle*. Don't worry if it doesn't make much sense, or if your solution looks very different to it. There are *many* ways of solving this problem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "ypYL6RgUI5lA"
      },
      "outputs": [],
      "source": [
        "def fluttering_agent(y_coord, angle, distance, height):\n",
        "  if distance \u003e= 140:\n",
        "    if angle \u003e 120:\n",
        "      return 1\n",
        "  if distance \u003c 140:\n",
        "    if height + 25 \u003c y_coord:\n",
        "      return 1\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfuasldnISWp"
      },
      "source": [
        "## Test your manually coded agent!\n",
        "\n",
        "Let's try out the agent you just coded to see how it performs in the game:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fT60y-GJF4Fv"
      },
      "outputs": [],
      "source": [
        "#@title Run your agent!\n",
        "\n",
        "\n",
        "class ManualAgent(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def _state_from_obs(self, observation):\n",
        "    x = observation['Features']['x']\n",
        "    y = observation['Features']['y']\n",
        "    for i, p in enumerate(observation['Features']['pipes']):\n",
        "      if p[0] \u003e x:\n",
        "        next_p = observation['Features']['pipes'][i]\n",
        "        break\n",
        "    for i, p in enumerate(observation['Features']['pipes']):\n",
        "      if p[0] \u003e x and p[0] \u003c next_p[0]:\n",
        "        next_p = observation['Features']['pipes'][i]\n",
        "    angle = observation['Features']['angle']\n",
        "    # Hand crafted feature of distance to next pipe, y, angle and hole position.\n",
        "    return [y, angle, next_p[0] - x, next_p[1]]\n",
        "\n",
        "  def step(self, observation):\n",
        "    \"\"\"Evaluate the policy of the agent given an observation.\n",
        "\n",
        "    Returns:\n",
        "      logit for whether the 'up' action is taken.\n",
        "    \"\"\"\n",
        "    state = self._state_from_obs(observation)\n",
        "    return fluttering_agent(*state)\n",
        "\n",
        "\n",
        "\n",
        "trace = get_trace(ManualAgent(), env)\n",
        "fig, ax, image = prepare_animation()\n",
        "\n",
        "def update(frame):\n",
        "    image.set_data(np.asarray(trace[frame]['Pixels']))\n",
        "    return image, \n",
        "\n",
        "anim = animation.FuncAnimation(fig, update, frames=range(len(trace)), blit=True,\n",
        "                               interval=50)\n",
        "\n",
        "plt.close()\n",
        "rc('animation', html='jshtml')\n",
        "anim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZZlyK-5Fe7T"
      },
      "source": [
        "# How to train your agent\n",
        "\n",
        "Don't worry if you are not familiar with programming. The whole point is that we want to use machine learning to make the computer learn on its own!\n",
        "\n",
        "How would a computer do *that*?\n",
        "\n",
        "Well, the computer will not write code like we do (although some researchers are working on that problem!). Instead, the computer will create a function with a whole lot of **parameters**, which are like little knobs and switches that can make it create just about any function we can think of. Then, over time, it will adapt those **parameters** based on its experience to make the function better and better at what it does.\n",
        "\n",
        "A very popular choice nowadays is what we call an **Artificial Neural Network**. Similar to our brains, which are composed of a bunch of neurons, each of which is not that sophisticated, but that jointly end up making up whole human brains. Our *artificial neurons* are much simpler than real ones, and we will not have billions of them, but just a handful. Regardless, it will be enough to conquer Fluttering Avians!\n",
        "\n",
        "So, we will now replace our black box, with an artificial neural network like the one depicted below. Don't worry too much about the details. Just notice that the neurons are taking the same inputs that our black box function did above, and they output whether we should flutter or not.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/ann.png\" width=\"500\"/\u003e\n",
        "\u003c/center\u003e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "f7qd1FVTzKGZ"
      },
      "outputs": [],
      "source": [
        "#@title Define an Agent using an Artificial Neural Network\n",
        "\n",
        "def relu(x):\n",
        "  return x if x \u003e 0 else 0\n",
        "\n",
        "def logistic(x, shape=1):\n",
        "  value = x*shape\n",
        "  if value \u003e 100:\n",
        "    return 1\n",
        "  if value \u003c -100:\n",
        "    return 0\n",
        "  return math.exp(value) / (1 + math.exp(value))\n",
        "\n",
        "class Agent(object):\n",
        "  def __init__(self,\n",
        "               obs_spec: dict,\n",
        "               act_spec: dm_env.specs.DiscreteArray,\n",
        "               num_hidden: int):\n",
        "    num_inputs = 4\n",
        "\n",
        "    # initialise parameters between -1 and 1, uniformly.\n",
        "    # Of the hidden layer; and\n",
        "    self._params_hidden = 2 * np.random.random_sample(\n",
        "        (num_hidden, int(num_inputs) + 1)) - 1\n",
        "\n",
        "    # Of the output layer; and\n",
        "    self._params_output = 2 * np.random.random_sample(num_hidden + 1) - 1\n",
        "\n",
        "  def _state_from_obs(self, observation):\n",
        "    x = observation['Features']['x']\n",
        "    y = observation['Features']['y']\n",
        "    for i, p in enumerate(observation['Features']['pipes']):\n",
        "      if p[0] \u003e x:\n",
        "        next_p = observation['Features']['pipes'][i]\n",
        "        break\n",
        "    for i, p in enumerate(observation['Features']['pipes']):\n",
        "      if p[0] \u003e x and p[0] \u003c next_p[0]:\n",
        "        next_p = observation['Features']['pipes'][i]\n",
        "    angle = observation['Features']['angle']\n",
        "    # Hand crafted feature of distance to next pipe, y, angle and hole position.\n",
        "    return [next_p[0] - x, y, angle, next_p[1], 1.]\n",
        "\n",
        "  def step(self, observation):\n",
        "    \"\"\"Evaluate the policy of the agent given an observation.\n",
        "\n",
        "    Returns:\n",
        "      logit for whether the 'up' action is taken.\n",
        "    \"\"\"\n",
        "    state = self._state_from_obs(observation)\n",
        "\n",
        "    hidden = np.matmul(self._params_hidden, state)\n",
        "    hidden = np.array([relu(x) for x in hidden])\n",
        "    hidden = np.concatenate([hidden, [1.]])  # for bias in output layer\n",
        "    output = np.dot(hidden, self._params_output)\n",
        "    return logistic(output)\n",
        "\n",
        "  def mutate(self, sigma: float = 0.05):\n",
        "    self._params_hidden += np.random.normal(0, sigma, self._params_hidden.shape)\n",
        "    self._params_output += np.random.normal(0, sigma, self._params_output.shape)\n",
        "\n",
        "  def copy_from(self, agent: 'Agent'):\n",
        "    np.copyto(self._params_hidden, agent._params_hidden)\n",
        "    np.copyto(self._params_output, agent._params_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def eval_agent(\n",
        "    agent: Agent, env: dm_env.Environment, max_fitness: int = 200) -\u003e float:\n",
        "  \"\"\"Get the fitness of the given agent policy.\"\"\"\n",
        "  fitness = 0\n",
        "  ts = env.reset()\n",
        "  while ts.step_type != dm_env.StepType.LAST and fitness \u003c max_fitness:\n",
        "    fitness += 1\n",
        "    policy_val = agent.step(ts.observation)\n",
        "    action = 1 if policy_val \u003e 0.5 else 0\n",
        "    ts = env.step(action)\n",
        "  return fitness\n",
        "\n",
        "def eval_population(\n",
        "    population: list, env: dm_env.Environment, replicas: int = 10,\n",
        "    ) -\u003e np.ndarray:\n",
        "  fitness = np.zeros((len(population),))\n",
        "  for i, ag in enumerate(population):\n",
        "    for _ in range(replicas):\n",
        "      fitness[i] += eval_agent(ag, env)\n",
        "  return fitness / replicas\n",
        "\n",
        "def init_population(pop_size, num_hidden, env):\n",
        "  return [Agent(env.observation_spec(), env.action_spec(), num_hidden)\n",
        "          for _ in range(pop_size)]\n",
        "\n",
        "def selection(population, new_pop, env, sigma=0.1, mu=0.4):\n",
        "  pop_size = len(population)\n",
        "  fitness = eval_population(population, env)\n",
        "\n",
        "  best = population[np.argmax(fitness)]\n",
        "\n",
        "  # Get fitness by order\n",
        "  order = sorted(enumerate(fitness), key=lambda x: x[1])\n",
        "  # assign pseudo fitness based on ranking.\n",
        "  pseudo_f = np.zeros((pop_size,))\n",
        "  for i, pair in enumerate(order):\n",
        "    pseudo_f[pair[0]] = i\n",
        "  choices = np.random.choice(pop_size, size=pop_size,\n",
        "                             replace=True, p=pseudo_f/sum(pseudo_f))\n",
        "  for i in range(pop_size):\n",
        "    new_pop[i].copy_from(population[choices[i]])\n",
        "    if np.random.random_sample() \u003c mu:\n",
        "      new_pop[i].mutate(sigma)\n",
        "\n",
        "  return fitness, best\n",
        "\n",
        "def run_agent(agent, env, delay=0.05, ignore_result=True):\n",
        "  ts = env.reset()\n",
        "  while ts.step_type != dm_env.StepType.LAST:\n",
        "    policy_val = agent.step(ts.observation)\n",
        "    action = 1 if policy_val \u003e 0.5 else 0\n",
        "    ts = env.step(action)\n",
        "    src = 'data:image/png;base64,{}'.format(encode_observation(ts))\n",
        "    output.eval_js(\n",
        "        f'document.getElementById(\"img\").setAttribute(\"src\", \"{src}\")',\n",
        "        ignore_result=ignore_result)\n",
        "    if delay:\n",
        "      time.sleep(delay)\n",
        "\n",
        "\n",
        "agent = Agent(env.observation_spec(), env.action_spec(), num_hidden=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbn7Un8XQxwh"
      },
      "source": [
        "The cell above creates an *agent* that has an artificial neural network inside, like the one in the image above, and that knows how to interact with our Fluttering Avians environment.\n",
        "\n",
        "-----\n",
        "\n",
        "Now, let's see how well it does in the game!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7JgqopE1Rct4"
      },
      "outputs": [],
      "source": [
        "#@title Run the agent!\n",
        "\n",
        "trace = get_trace(agent, env)\n",
        "fig, ax, image = prepare_animation()\n",
        "\n",
        "def update(frame):\n",
        "    image.set_data(np.asarray(trace[frame]['Pixels']))\n",
        "    return image, \n",
        "\n",
        "anim = animation.FuncAnimation(fig, update, frames=range(len(trace)), blit=True,\n",
        "                               interval=50)\n",
        "\n",
        "plt.close()\n",
        "rc('animation', html='jshtml')\n",
        "anim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X14EnGR9Rj9e"
      },
      "source": [
        "Not that smart, sadly! This is because the agent is not learning yet. This is its very first interaction with the world. It is much less capable than even a newborn baby... in fact, it is acting essentially at random."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7bkMSVUSGLS"
      },
      "source": [
        "# Train Fluttering Avians"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpboTQX1PXIf"
      },
      "source": [
        "Ok, we've created an agent, but we still haven't figured out how it will change all its internal switches and knobs (its parameters). This is where the crux of machine learning lies!\n",
        "\n",
        "There are many, many (many!) ways to do this, and it is not clear that one of them is always better than the other. This is an active area of research where we still don't know the best solutions (also called **algorithms**). How very exciting, huh?! Maybe *you* will come up with a better solution than the ones we have! Why not?\n",
        "\n",
        "One of the most famous techniques to solve these kinds of problems is *Reinforcement Learning* (of which DeepMind does quite a bit). However, here we will use something different: we will use a solution from the family of *Evolutionary Algorithms* (or *EAs*).\n",
        "\n",
        "## Evolutionary Algorithms\n",
        "\n",
        "Instead of having a single agent that tries to solve the game, we will have a whole bunch of them, a **population**.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/population.png\" width=\"300\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "Each of the agents will play the game for a while. We will keep track of which agents get further in the game than the others. That is, we will **evaluate** them.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/evaluation.png\" width=\"300\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "Then, we will remove the worst performing agents to make space for new agents to try to solve the game. The new agents will be descendants of the best performing agents of the previous generation. That is, agents will **reproduce** over time.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/reproduction.png\" width=\"300\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "The best agents reproduce more than worse ones. When an agent reproduces, their *offspring* are not an exact copy of their parents (what would the point of that!?), instead, we will wiggle their internal parameters a little bit in the hope that they discover something new. That is, they will **mutate**.\n",
        "\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://storage.googleapis.com/dm-educational/assets/FlutteringAvians/mutation.png\" width=\"300\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "-----\n",
        "\n",
        "And that's it! We just repeat this process over and over until we get a good solution! These algorithms are called *Evolutionary* because they roughly mimic the process of evolution through natural selection.\n",
        "\n",
        "## Evolution on a population to train an agent\n",
        "\n",
        "Now we are ready to train some agents!\n",
        "\n",
        "You can choose below how many agents there will be in your population, and how many neurons each of them will have. Run the cell to create the population.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PrBZGqwPyAPN"
      },
      "outputs": [],
      "source": [
        "#@title Initialise the population\n",
        "\n",
        "#@markdown This is the number of agents in the population. The larger it is, the\n",
        "#@markdown more diversity of behaviours we will see, but the slower it will run.\n",
        "population_size = 50 #@param {type:\"slider\", min:10, max:100, step:10}\n",
        "\n",
        "#@markdown This is the number of internal (or *hidden*) neurons in each agent's\n",
        "#@markdown artificial brain.\n",
        "number_of_hidden_neurons = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "train_env = FlutteringAvians(render_pixels=False)  \n",
        "pop = init_population(population_size, number_of_hidden_neurons, train_env)\n",
        "new_pop = init_population(population_size, number_of_hidden_neurons, train_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_eu5yu0UdzD"
      },
      "source": [
        "OK, now that we have a population, we can do a few generations of the algorithm. We'll keep track of the best agent so far so we can see its progress.\n",
        "\n",
        "You can re-run the cells below to train and see your best agent's performance. If you want to start over with a new population, just run the **Initialise population** cell above.\n",
        "\n",
        "----\n",
        "\n",
        "That's it! Try to get an agent that gets as close to 200 as you can. **Good luck!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g_8LQk6B2t9W"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate, select, reproduce and mutate!\n",
        "\n",
        "from google.colab import widgets\n",
        "grid = widgets.Grid(1, 1)\n",
        "\n",
        "#@markdown This is the number of generations that we will run our evolutionary\n",
        "#@markdown algorithm. The larger the number, the better (usually) our agents\n",
        "#@markdown will get. More generations will take longer to run. (Remember you can\n",
        "#@markdown re-run this cell to keep training anyway).\n",
        "generations = 30 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "\n",
        "#@markdown This is the probability that any new agent (i.e. the products of\n",
        "#@markdown reproduction) will change its parameters.\n",
        "mutation_rate = 0.6 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "#@markdown This is the amount of wiggle that a mutation will cause in an agent's\n",
        "#@markdown parameters. Larger makes more exploration of new behaviours, but too\n",
        "#@markdown large might break good behaviours that are already there.\n",
        "mutation_intensity = 0.08 #@param {type:\"slider\", min:0.01, max:0.5, step:0.01}\n",
        "\n",
        "#@markdown Whether to plot the performance of the best agent in the population.\n",
        "plot_best = True #@param {type:\"boolean\"}\n",
        "\n",
        "def plot_fitnesses(i, all_fitness):\n",
        "  axes = plt.subplot()\n",
        "  axes.set_title('Agent performance')\n",
        "  axes.set_xlabel('Generation')\n",
        "  axes.set_ylabel('Score')\n",
        "  if plot_best:\n",
        "    axes.plot(range(i+1), [np.max(f) for f in all_fitness], label='Best',\n",
        "              linestyle='--')\n",
        "  axes.plot(range(i+1), [np.mean(f) for f in all_fitness], label='Mean')\n",
        "  axes.fill_between(range(i+1),\n",
        "                    [np.percentile(f, 5) for f in all_fitness],\n",
        "                    [np.percentile(f, 95) for f in all_fitness], alpha=0.4)\n",
        "  axes.legend()\n",
        "  return axes\n",
        "\n",
        "# List of all fitness values over time.\n",
        "fitness_all = []\n",
        "\n",
        "with grid.output_to(0, 0):\n",
        "  grid.clear_cell()\n",
        "  plot_fitnesses(-1, fitness_all)\n",
        "\n",
        "for i in range(generations):\n",
        "  fitness, best = selection(\n",
        "      pop, new_pop, train_env, mutation_intensity, mutation_rate)\n",
        "  fitness_all.append(fitness)\n",
        "  with grid.output_to(0, 0):\n",
        "    grid.clear_cell()\n",
        "    plot_fitnesses(i, fitness_all)\n",
        "\n",
        "  # print('fitness', list(reversed(sorted(fitness))))\n",
        "  # Swap populations\n",
        "  new_pop, pop = pop, new_pop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YnUU7wCVEssp"
      },
      "outputs": [],
      "source": [
        "#@title Run the best agent in the population!\n",
        "\n",
        "trace = get_trace(best, env)\n",
        "fig, ax, image = prepare_animation()\n",
        "\n",
        "def update(frame):\n",
        "    image.set_data(np.asarray(trace[frame]['Pixels']))\n",
        "    return image, \n",
        "\n",
        "anim = animation.FuncAnimation(fig, update, frames=range(len(trace)), blit=True,\n",
        "                               interval=50)\n",
        "\n",
        "plt.close()\n",
        "rc('animation', html='jshtml')\n",
        "anim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKnt-TSRkfiD"
      },
      "source": [
        "# THE END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cF8rLdiBIf-j"
      ],
      "name": "Fluttering Avians.ipynb",
      "provenance": [
        {
          "file_id": "1jL4x4uizNuyTNMWdyKvuYlC7Bd78H9nD",
          "timestamp": 1593786501759
        },
        {
          "file_id": "1mAnCiylriol3FBfmcJUH8QBx8hecJhoE",
          "timestamp": 1592840683558
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
